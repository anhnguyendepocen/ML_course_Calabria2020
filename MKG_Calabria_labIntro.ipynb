{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "version": "3.7.6-final"
    },
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "MKG_Calabria_labIntro",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkgerullis/ML_course_Calabria2020/blob/master/MKG_Calabria_labIntro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k10_r9GL8YlT",
        "colab_type": "text"
      },
      "source": [
        "### Intro notebook for the course: \"Machine Learning for Applied Economics and Policy\"\n",
        "\n",
        "#### Instructors\n",
        "- Kathy Baylis\n",
        "- Giovanni Cerulli\n",
        "- Gianluigi Greco\n",
        "- Thomas Heckelei\n",
        "- Hugo Storm\n",
        "\n",
        "#### Description\n",
        "This notebook is intended to get you familliar with some of the most common data science / ML libaries typically used in python. \n",
        "In this notebook you will 1) load data, 2) prepare the data for running your models, 3) run a simple logistic regression, 4) run a very simiple neural network, and 5) compare the results of the two models. You will learn in the course that a logistic regression is actually a special case of a very simple neural network! So if you have run a logistic regression you have actually worked with NN... \n",
        "\n",
        "Work Steps\n",
        "\n",
        "1. Open this notebook in google colab (https://colab.research.google.com/) using the link provided above. To run the notebook you need to have a google account. \n",
        "\n",
        "2. Execute all code cells and try to understand what is going on.\n",
        "\n",
        "3. Two important python libaries for working with data in python are numpy and pandas \n",
        "    There are plenty of tutorials online to get you a first idea of how they work. Two examples are provided here. For taking the course you do not have to be an expert in using those libaries but having a first basic understanding of the functionality will centainly help you to follow the examples. \n",
        "    \n",
        "- Numpy: https://www.datacamp.com/community/tutorials/python-numpy-tutorial\n",
        "\n",
        "- Pandas: https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html#min   \n",
        "\n",
        "4. (Optional) Play around with the notebook and make some changes (no worries you can not break it...). Here a some ideas what you can try to achieve:\n",
        "\n",
        "- In the data set there are many more variables. Figure out how they are named and add a couple more variables to two models. Run the models and see how this changes the quality of the model prediction (in terms of R²). \n",
        "\n",
        "-  If you want to go a step further... Create some new variables by adding interaction terms or square/cube terms. See if this increases model performance (R²).\n",
        "\n",
        "- Are you up for the challange (before even starting with the course)? The sklearn libary implements a large number of ML models. We will cover the most important ones in this course. In this notebook you have already seen how to use the logistic regression or a neural network in sklearn. Try to adjust the code to run an additional model, for example a random forest (will be covered on day 2 in the course). There are plenty of tutorials online (for example https://www.datacamp.com/community/tutorials/random-forests-classifier-python). Hint: there is basically only one line of code that you need to change in order to run an random forest with sklearn instead of a logistic regression. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9uNLCh58YlU",
        "colab_type": "text"
      },
      "source": [
        "#### Load relevant libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_wnzeZx8YlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import scipy.stats as stat\n",
        "from scipy.stats import norm\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01gwbHWy8Ylc",
        "colab_type": "text"
      },
      "source": [
        "#### Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rQhcbrS8Ylh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "e961dc9e-8f63-4af9-f864-2148553e829a"
      },
      "source": [
        "# Download data\n",
        "!wget http://www.ilr.uni-bonn.de/agpo/courses/ml/brazil_all_data_v2.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-06 08:45:40--  http://www.ilr.uni-bonn.de/agpo/courses/ml/brazil_all_data_v2.csv\n",
            "Resolving www.ilr.uni-bonn.de (www.ilr.uni-bonn.de)... 131.220.69.2\n",
            "Connecting to www.ilr.uni-bonn.de (www.ilr.uni-bonn.de)|131.220.69.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 789226067 (753M) [application/octet-stream]\n",
            "Saving to: ‘brazil_all_data_v2.csv’\n",
            "\n",
            "brazil_all_data_v2. 100%[===================>] 752.66M  5.95MB/s    in 2m 11s  \n",
            "\n",
            "2020-07-06 08:47:51 (5.73 MB/s) - ‘brazil_all_data_v2.csv’ saved [789226067/789226067]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfWHYVAT8Ylk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data with pandas into a dataframe \n",
        "df = pd.read_csv('brazil_all_data_v2.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WUBlF368Ylr",
        "colab_type": "text"
      },
      "source": [
        "#### Setup dependent and explantory variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivZFEoz28Yls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define binary variable for deforestration\n",
        "df['D_defor_2018'] = df['defor_2018']>0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWl0aefa8Ylx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add a constant to the dataframe\n",
        "df['constant'] = 1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8gzlvci8Yl1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "936c1eda-3d87-4919-915c-2dcf2fed28a3"
      },
      "source": [
        "# View first 5 rows of the data\n",
        "df.head(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>row</th>\n",
              "      <th>col</th>\n",
              "      <th>lon</th>\n",
              "      <th>lat</th>\n",
              "      <th>bean</th>\n",
              "      <th>carrot</th>\n",
              "      <th>cassava</th>\n",
              "      <th>chickpea</th>\n",
              "      <th>citrus</th>\n",
              "      <th>coffee</th>\n",
              "      <th>groundnut</th>\n",
              "      <th>maize</th>\n",
              "      <th>soy</th>\n",
              "      <th>sugarcane</th>\n",
              "      <th>tomato</th>\n",
              "      <th>wheat</th>\n",
              "      <th>perc_treecover</th>\n",
              "      <th>perm_water</th>\n",
              "      <th>travel_min</th>\n",
              "      <th>defor_2001</th>\n",
              "      <th>defor_2002</th>\n",
              "      <th>defor_2003</th>\n",
              "      <th>defor_2004</th>\n",
              "      <th>defor_2005</th>\n",
              "      <th>defor_2006</th>\n",
              "      <th>defor_2007</th>\n",
              "      <th>defor_2008</th>\n",
              "      <th>defor_2009</th>\n",
              "      <th>defor_2010</th>\n",
              "      <th>defor_2011</th>\n",
              "      <th>defor_2012</th>\n",
              "      <th>defor_2013</th>\n",
              "      <th>defor_2014</th>\n",
              "      <th>defor_2015</th>\n",
              "      <th>defor_2016</th>\n",
              "      <th>defor_2017</th>\n",
              "      <th>defor_2018</th>\n",
              "      <th>wdpa_1990</th>\n",
              "      <th>wdpa_1991</th>\n",
              "      <th>...</th>\n",
              "      <th>tot_defor_2018_lag_1st_order</th>\n",
              "      <th>tot_defor_2001_lag_2nd_order</th>\n",
              "      <th>tot_defor_2002_lag_2nd_order</th>\n",
              "      <th>tot_defor_2003_lag_2nd_order</th>\n",
              "      <th>tot_defor_2004_lag_2nd_order</th>\n",
              "      <th>tot_defor_2005_lag_2nd_order</th>\n",
              "      <th>tot_defor_2006_lag_2nd_order</th>\n",
              "      <th>tot_defor_2007_lag_2nd_order</th>\n",
              "      <th>tot_defor_2008_lag_2nd_order</th>\n",
              "      <th>tot_defor_2009_lag_2nd_order</th>\n",
              "      <th>tot_defor_2010_lag_2nd_order</th>\n",
              "      <th>tot_defor_2011_lag_2nd_order</th>\n",
              "      <th>tot_defor_2012_lag_2nd_order</th>\n",
              "      <th>tot_defor_2013_lag_2nd_order</th>\n",
              "      <th>tot_defor_2014_lag_2nd_order</th>\n",
              "      <th>tot_defor_2015_lag_2nd_order</th>\n",
              "      <th>tot_defor_2016_lag_2nd_order</th>\n",
              "      <th>tot_defor_2017_lag_2nd_order</th>\n",
              "      <th>tot_defor_2018_lag_2nd_order</th>\n",
              "      <th>tot_defor_2001_lag_3rd_order</th>\n",
              "      <th>tot_defor_2002_lag_3rd_order</th>\n",
              "      <th>tot_defor_2003_lag_3rd_order</th>\n",
              "      <th>tot_defor_2004_lag_3rd_order</th>\n",
              "      <th>tot_defor_2005_lag_3rd_order</th>\n",
              "      <th>tot_defor_2006_lag_3rd_order</th>\n",
              "      <th>tot_defor_2007_lag_3rd_order</th>\n",
              "      <th>tot_defor_2008_lag_3rd_order</th>\n",
              "      <th>tot_defor_2009_lag_3rd_order</th>\n",
              "      <th>tot_defor_2010_lag_3rd_order</th>\n",
              "      <th>tot_defor_2011_lag_3rd_order</th>\n",
              "      <th>tot_defor_2012_lag_3rd_order</th>\n",
              "      <th>tot_defor_2013_lag_3rd_order</th>\n",
              "      <th>tot_defor_2014_lag_3rd_order</th>\n",
              "      <th>tot_defor_2015_lag_3rd_order</th>\n",
              "      <th>tot_defor_2016_lag_3rd_order</th>\n",
              "      <th>tot_defor_2017_lag_3rd_order</th>\n",
              "      <th>tot_defor_2018_lag_3rd_order</th>\n",
              "      <th>s</th>\n",
              "      <th>D_defor_2018</th>\n",
              "      <th>constant</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-59.989876</td>\n",
              "      <td>-10.010125</td>\n",
              "      <td>200.00000</td>\n",
              "      <td>335.00000</td>\n",
              "      <td>201.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>391.0</td>\n",
              "      <td>237.00000</td>\n",
              "      <td>115.0</td>\n",
              "      <td>461.00000</td>\n",
              "      <td>209.00000</td>\n",
              "      <td>1295.0000</td>\n",
              "      <td>357.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>99.761093</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2612.6440</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009531</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000312</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000625</td>\n",
              "      <td>0.000312</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009531</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.625000</td>\n",
              "      <td>26.499998</td>\n",
              "      <td>17.500000</td>\n",
              "      <td>2.625000</td>\n",
              "      <td>2.125000</td>\n",
              "      <td>37.375000</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>11.625000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>4.125000</td>\n",
              "      <td>4.875000</td>\n",
              "      <td>4.250000</td>\n",
              "      <td>9.875000</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>14.333333</td>\n",
              "      <td>9.800000</td>\n",
              "      <td>1.533333</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>6.866667</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>4.466667</td>\n",
              "      <td>9.866667</td>\n",
              "      <td>6.600000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-59.969875</td>\n",
              "      <td>-10.010125</td>\n",
              "      <td>200.00000</td>\n",
              "      <td>335.00000</td>\n",
              "      <td>201.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>391.0</td>\n",
              "      <td>237.00000</td>\n",
              "      <td>115.0</td>\n",
              "      <td>461.00000</td>\n",
              "      <td>209.00000</td>\n",
              "      <td>1295.0000</td>\n",
              "      <td>357.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>99.777657</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2680.3191</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013125</td>\n",
              "      <td>0.008437</td>\n",
              "      <td>0.011875</td>\n",
              "      <td>0.003125</td>\n",
              "      <td>0.000781</td>\n",
              "      <td>0.046719</td>\n",
              "      <td>0.001094</td>\n",
              "      <td>0.002812</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002188</td>\n",
              "      <td>0.000625</td>\n",
              "      <td>0.002344</td>\n",
              "      <td>0.006094</td>\n",
              "      <td>0.000937</td>\n",
              "      <td>0.006562</td>\n",
              "      <td>0.001406</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>19.999998</td>\n",
              "      <td>5.818181</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>1.363636</td>\n",
              "      <td>1.545454</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>1.818182</td>\n",
              "      <td>7.909091</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>1.636364</td>\n",
              "      <td>1.272727</td>\n",
              "      <td>12.909090</td>\n",
              "      <td>10.181818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>12.052631</td>\n",
              "      <td>3.842105</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>0.894737</td>\n",
              "      <td>0.894737</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.052631</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.105263</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>1.473684</td>\n",
              "      <td>9.473684</td>\n",
              "      <td>6.210527</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-59.949875</td>\n",
              "      <td>-10.010125</td>\n",
              "      <td>200.00000</td>\n",
              "      <td>335.00000</td>\n",
              "      <td>201.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>391.0</td>\n",
              "      <td>237.00000</td>\n",
              "      <td>115.0</td>\n",
              "      <td>461.00000</td>\n",
              "      <td>209.00000</td>\n",
              "      <td>1295.0000</td>\n",
              "      <td>357.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>99.766403</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2796.3284</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024531</td>\n",
              "      <td>0.009375</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000312</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001719</td>\n",
              "      <td>0.005313</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.173913</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.214286</td>\n",
              "      <td>8.785713</td>\n",
              "      <td>5.857143</td>\n",
              "      <td>1.642857</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>22.571428</td>\n",
              "      <td>1.785714</td>\n",
              "      <td>2.214286</td>\n",
              "      <td>2.571429</td>\n",
              "      <td>7.142858</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.357143</td>\n",
              "      <td>3.785714</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>8.571429</td>\n",
              "      <td>3.142857</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>1.826087</td>\n",
              "      <td>6.869565</td>\n",
              "      <td>7.086957</td>\n",
              "      <td>8.260869</td>\n",
              "      <td>1.782609</td>\n",
              "      <td>4.347826</td>\n",
              "      <td>18.043478</td>\n",
              "      <td>1.956522</td>\n",
              "      <td>3.652174</td>\n",
              "      <td>1.652174</td>\n",
              "      <td>5.913043</td>\n",
              "      <td>4.086957</td>\n",
              "      <td>4.521739</td>\n",
              "      <td>4.956522</td>\n",
              "      <td>8.695652</td>\n",
              "      <td>11.217392</td>\n",
              "      <td>5.173913</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>-59.929874</td>\n",
              "      <td>-10.010125</td>\n",
              "      <td>200.00000</td>\n",
              "      <td>335.00000</td>\n",
              "      <td>201.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>391.0</td>\n",
              "      <td>237.00000</td>\n",
              "      <td>115.0</td>\n",
              "      <td>461.00000</td>\n",
              "      <td>209.00000</td>\n",
              "      <td>1295.0000</td>\n",
              "      <td>357.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>99.814842</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2920.0164</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000469</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002188</td>\n",
              "      <td>0.017812</td>\n",
              "      <td>0.000469</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>6.518518</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>2.928571</td>\n",
              "      <td>11.285714</td>\n",
              "      <td>18.214285</td>\n",
              "      <td>17.214285</td>\n",
              "      <td>2.928571</td>\n",
              "      <td>6.142857</td>\n",
              "      <td>28.428572</td>\n",
              "      <td>3.142857</td>\n",
              "      <td>5.357143</td>\n",
              "      <td>2.785714</td>\n",
              "      <td>8.428572</td>\n",
              "      <td>5.857142</td>\n",
              "      <td>7.214285</td>\n",
              "      <td>6.142857</td>\n",
              "      <td>6.785714</td>\n",
              "      <td>15.785715</td>\n",
              "      <td>8.214286</td>\n",
              "      <td>1.222222</td>\n",
              "      <td>2.777778</td>\n",
              "      <td>5.925926</td>\n",
              "      <td>12.185184</td>\n",
              "      <td>10.740741</td>\n",
              "      <td>2.074074</td>\n",
              "      <td>4.370370</td>\n",
              "      <td>15.555556</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>3.814815</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>5.407407</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.925926</td>\n",
              "      <td>3.703704</td>\n",
              "      <td>5.888889</td>\n",
              "      <td>19.629629</td>\n",
              "      <td>6.518518</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>-59.909874</td>\n",
              "      <td>-10.010125</td>\n",
              "      <td>218.33334</td>\n",
              "      <td>435.83334</td>\n",
              "      <td>216.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>523.5</td>\n",
              "      <td>317.83331</td>\n",
              "      <td>117.5</td>\n",
              "      <td>522.66663</td>\n",
              "      <td>233.16666</td>\n",
              "      <td>1300.8334</td>\n",
              "      <td>482.83331</td>\n",
              "      <td>0.0</td>\n",
              "      <td>99.655937</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2977.4216</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000469</td>\n",
              "      <td>0.000312</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005625</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005469</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.222222</td>\n",
              "      <td>2.357143</td>\n",
              "      <td>5.285714</td>\n",
              "      <td>5.285714</td>\n",
              "      <td>14.785714</td>\n",
              "      <td>14.357142</td>\n",
              "      <td>2.571429</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>7.571428</td>\n",
              "      <td>2.642857</td>\n",
              "      <td>5.285714</td>\n",
              "      <td>3.857143</td>\n",
              "      <td>3.642857</td>\n",
              "      <td>6.142857</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.357143</td>\n",
              "      <td>15.285714</td>\n",
              "      <td>29.714287</td>\n",
              "      <td>9.142857</td>\n",
              "      <td>10.185184</td>\n",
              "      <td>3.111111</td>\n",
              "      <td>5.925926</td>\n",
              "      <td>9.777778</td>\n",
              "      <td>10.740741</td>\n",
              "      <td>2.148148</td>\n",
              "      <td>4.111111</td>\n",
              "      <td>15.000001</td>\n",
              "      <td>1.851852</td>\n",
              "      <td>8.296296</td>\n",
              "      <td>2.629630</td>\n",
              "      <td>5.222222</td>\n",
              "      <td>7.592592</td>\n",
              "      <td>5.370370</td>\n",
              "      <td>4.481482</td>\n",
              "      <td>8.888889</td>\n",
              "      <td>18.888889</td>\n",
              "      <td>5.222222</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 428 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  row  col  ...  s  D_defor_2018  constant\n",
              "0   0    0    0  ...  1         False         1\n",
              "1   1    0    1  ...  1          True         1\n",
              "2   2    0    2  ...  1         False         1\n",
              "3   3    0    3  ...  1         False         1\n",
              "4   4    0    4  ...  1          True         1\n",
              "\n",
              "[5 rows x 428 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WU_yntf8Yl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the dependent variable\n",
        "Y = df['D_defor_2018']\n",
        "# Define a list of variable names for explanatory varibales\n",
        "lstCols = [\n",
        "  'wdpa_2017',\n",
        "  'population_2015',\n",
        "  'chirps_2017',\n",
        "  'defor_2017',\n",
        "  'maize',\n",
        "  'soy',\n",
        "  'sugarcane',\n",
        "  'perc_treecover',\n",
        "  'perm_water',\n",
        "  'travel_min',\n",
        "  'cropland',\n",
        "  # 'pasture',\n",
        "  'mean_elev',\n",
        "  'sd_elev',\n",
        "  'near_road',\n",
        "  'defor_2017_lag_1st_order',\n",
        "  'wdpa_2017_lag_1st_order',\n",
        "  'chirps_2017_lag_1st_order',\n",
        "  'population_2015_lag_1st_order',\n",
        "  'maize_lag_1st_order',\n",
        "  'soy_lag_1st_order',\n",
        "  'sugarcane_lag_1st_order',\n",
        "  'perc_treecover_lag_1st_order',\n",
        "  'perm_water_lag_1st_order',\n",
        "  'travel_min_lag_1st_order',\n",
        "  'cropland_lag_1st_order',\n",
        "  # 'pasture_lag_1st_order',\n",
        "  'mean_elev_lag_1st_order',\n",
        "  'sd_elev_lag_1st_order',\n",
        "  'near_road_lag_1st_order',\n",
        "#  'bean',\n",
        "#  'carrot',\n",
        "#  'cassava',\n",
        "#  'chickpea',\n",
        "#  'citrus',\n",
        "#  'coffee',\n",
        "#  'groundnut',\n",
        "#  'maize',\n",
        "#  'soy',\n",
        "#  'sugarcane',\n",
        "#  'tomato',\n",
        "#  'wheat',\n",
        "#  'defor_2001',\n",
        "#  'defor_2002',\n",
        "#  'defor_2003',\n",
        "#  'defor_2004',\n",
        "#  'defor_2005',\n",
        "#  'defor_2006',\n",
        "#  'defor_2007',\n",
        "#  'defor_2008',\n",
        "#  'defor_2009',\n",
        "#  'defor_2010',\n",
        "#  'defor_2011',\n",
        "#  'defor_2012',\n",
        "#  'defor_2013',\n",
        "#  'defor_2014',\n",
        "#  'defor_2015',\n",
        "#  'defor_2016',\n",
        "#  'defor_2017',\n",
        "#  'near_dist_km',\n",
        "#  'mean_elev_mts',\n",
        "#  'sd_elev_mts',\n",
        " ]\n",
        "\n",
        "# Get the explanatory Variables\n",
        "X =  df.loc[:,lstCols]\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgPj9lkr8Yl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data into train and test data using sklearn train_test_split object\n",
        "#   (see: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
        "\n",
        "#   Note: This randomly split the data in 80% train and 20% test data\n",
        "X_train_raw, X_test_raw, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVlC9obC8ggx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "388a7c8d-61e5-4ef5-91e1-c26120554b8b"
      },
      "source": [
        "X_train_raw.head(5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wdpa_2017</th>\n",
              "      <th>population_2015</th>\n",
              "      <th>chirps_2017</th>\n",
              "      <th>defor_2017</th>\n",
              "      <th>maize</th>\n",
              "      <th>soy</th>\n",
              "      <th>sugarcane</th>\n",
              "      <th>perc_treecover</th>\n",
              "      <th>perm_water</th>\n",
              "      <th>travel_min</th>\n",
              "      <th>cropland</th>\n",
              "      <th>mean_elev</th>\n",
              "      <th>sd_elev</th>\n",
              "      <th>near_road</th>\n",
              "      <th>defor_2017_lag_1st_order</th>\n",
              "      <th>wdpa_2017_lag_1st_order</th>\n",
              "      <th>chirps_2017_lag_1st_order</th>\n",
              "      <th>population_2015_lag_1st_order</th>\n",
              "      <th>maize_lag_1st_order</th>\n",
              "      <th>soy_lag_1st_order</th>\n",
              "      <th>sugarcane_lag_1st_order</th>\n",
              "      <th>perc_treecover_lag_1st_order</th>\n",
              "      <th>perm_water_lag_1st_order</th>\n",
              "      <th>travel_min_lag_1st_order</th>\n",
              "      <th>cropland_lag_1st_order</th>\n",
              "      <th>mean_elev_lag_1st_order</th>\n",
              "      <th>sd_elev_lag_1st_order</th>\n",
              "      <th>near_road_lag_1st_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>211019</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.743300</td>\n",
              "      <td>1140.8701</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>5145.0000</td>\n",
              "      <td>1725.00000</td>\n",
              "      <td>3498.0</td>\n",
              "      <td>95.500000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>386.034120</td>\n",
              "      <td>0.105000</td>\n",
              "      <td>233.27431</td>\n",
              "      <td>7.357755</td>\n",
              "      <td>3.982380</td>\n",
              "      <td>0.002949</td>\n",
              "      <td>0.033602</td>\n",
              "      <td>1153.6166</td>\n",
              "      <td>1.734069</td>\n",
              "      <td>4604.9746</td>\n",
              "      <td>1573.41600</td>\n",
              "      <td>3080.0693</td>\n",
              "      <td>88.958664</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>475.483760</td>\n",
              "      <td>0.074437</td>\n",
              "      <td>251.05762</td>\n",
              "      <td>12.067036</td>\n",
              "      <td>4.300830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152100</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.497108</td>\n",
              "      <td>1494.5341</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1418.8333</td>\n",
              "      <td>566.83337</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>0.321094</td>\n",
              "      <td>1.0</td>\n",
              "      <td>52.908264</td>\n",
              "      <td>0.019833</td>\n",
              "      <td>127.98780</td>\n",
              "      <td>1.093633</td>\n",
              "      <td>3.355971</td>\n",
              "      <td>0.002728</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1499.3014</td>\n",
              "      <td>0.540844</td>\n",
              "      <td>1446.2916</td>\n",
              "      <td>584.61456</td>\n",
              "      <td>2058.0938</td>\n",
              "      <td>17.326862</td>\n",
              "      <td>1.002894</td>\n",
              "      <td>71.333534</td>\n",
              "      <td>0.023635</td>\n",
              "      <td>128.69191</td>\n",
              "      <td>2.285338</td>\n",
              "      <td>2.511065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71133</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.120582</td>\n",
              "      <td>1922.1539</td>\n",
              "      <td>0.004062</td>\n",
              "      <td>1189.6666</td>\n",
              "      <td>700.00000</td>\n",
              "      <td>2763.0</td>\n",
              "      <td>90.612343</td>\n",
              "      <td>1.0</td>\n",
              "      <td>491.777890</td>\n",
              "      <td>0.011000</td>\n",
              "      <td>323.18399</td>\n",
              "      <td>7.377765</td>\n",
              "      <td>64.657524</td>\n",
              "      <td>0.004320</td>\n",
              "      <td>0.014956</td>\n",
              "      <td>1928.2488</td>\n",
              "      <td>0.095600</td>\n",
              "      <td>1189.5186</td>\n",
              "      <td>695.65045</td>\n",
              "      <td>2767.7256</td>\n",
              "      <td>89.219002</td>\n",
              "      <td>1.002949</td>\n",
              "      <td>639.929750</td>\n",
              "      <td>0.006477</td>\n",
              "      <td>316.10376</td>\n",
              "      <td>9.349813</td>\n",
              "      <td>64.806252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113252</th>\n",
              "      <td>0.938755</td>\n",
              "      <td>0.083385</td>\n",
              "      <td>1837.0503</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1189.0000</td>\n",
              "      <td>760.00000</td>\n",
              "      <td>2957.0</td>\n",
              "      <td>5.153281</td>\n",
              "      <td>1.0</td>\n",
              "      <td>218.281520</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>471.76910</td>\n",
              "      <td>14.875660</td>\n",
              "      <td>2.990992</td>\n",
              "      <td>0.002210</td>\n",
              "      <td>0.500785</td>\n",
              "      <td>1850.5565</td>\n",
              "      <td>0.086631</td>\n",
              "      <td>1160.1609</td>\n",
              "      <td>743.83160</td>\n",
              "      <td>2938.7192</td>\n",
              "      <td>13.188030</td>\n",
              "      <td>1.000645</td>\n",
              "      <td>238.731700</td>\n",
              "      <td>0.011638</td>\n",
              "      <td>446.91449</td>\n",
              "      <td>9.372373</td>\n",
              "      <td>2.360994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32717</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.340720</td>\n",
              "      <td>2036.5881</td>\n",
              "      <td>0.002656</td>\n",
              "      <td>1170.0000</td>\n",
              "      <td>631.00000</td>\n",
              "      <td>2845.0</td>\n",
              "      <td>92.805466</td>\n",
              "      <td>1.0</td>\n",
              "      <td>704.614990</td>\n",
              "      <td>0.004000</td>\n",
              "      <td>336.11801</td>\n",
              "      <td>9.273241</td>\n",
              "      <td>197.730700</td>\n",
              "      <td>0.027669</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2063.5518</td>\n",
              "      <td>0.690254</td>\n",
              "      <td>1148.6683</td>\n",
              "      <td>626.19678</td>\n",
              "      <td>2789.2783</td>\n",
              "      <td>77.084564</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>693.703980</td>\n",
              "      <td>0.002519</td>\n",
              "      <td>352.24255</td>\n",
              "      <td>10.586811</td>\n",
              "      <td>197.779630</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        wdpa_2017  ...  near_road_lag_1st_order\n",
              "211019   0.000000  ...                 4.300830\n",
              "152100   0.000000  ...                 2.511065\n",
              "71133    0.000000  ...                64.806252\n",
              "113252   0.938755  ...                 2.360994\n",
              "32717    0.000000  ...               197.779630\n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFhM3lFp8YmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale data to 0-1 range using sklearn MinMaxScalar object \n",
        "# (see: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) \n",
        "scaler = MinMaxScaler()\n",
        "# Use only the train data to fit the MinMaxScalar \n",
        "scaler.fit(X_train_raw)\n",
        "\n",
        "# Apply the MinMax transformation to the train and test data \n",
        "X_train = scaler.transform(X_train_raw)\n",
        "X_test = scaler.transform(X_test_raw)\n",
        "# Note the depended variable does not need to be scaled as it is a binary variable anyway"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCc0Axm79fvz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "e6f1415a-103a-4039-dfbe-8c9b4abaaae9"
      },
      "source": [
        "traindf = pd.DataFrame(X_train)\n",
        "traindf.head(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000264</td>\n",
              "      <td>0.162163</td>\n",
              "      <td>0.000157</td>\n",
              "      <td>0.813011</td>\n",
              "      <td>0.850299</td>\n",
              "      <td>0.555788</td>\n",
              "      <td>0.955000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.101330</td>\n",
              "      <td>0.105000</td>\n",
              "      <td>0.163486</td>\n",
              "      <td>0.035448</td>\n",
              "      <td>0.011118</td>\n",
              "      <td>0.006585</td>\n",
              "      <td>0.033602</td>\n",
              "      <td>0.169992</td>\n",
              "      <td>0.000790</td>\n",
              "      <td>0.740660</td>\n",
              "      <td>0.773393</td>\n",
              "      <td>0.466654</td>\n",
              "      <td>0.889646</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130121</td>\n",
              "      <td>0.077217</td>\n",
              "      <td>0.188011</td>\n",
              "      <td>0.122987</td>\n",
              "      <td>0.009348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>0.353761</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.215964</td>\n",
              "      <td>0.272372</td>\n",
              "      <td>0.316188</td>\n",
              "      <td>0.003211</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013660</td>\n",
              "      <td>0.019833</td>\n",
              "      <td>0.052599</td>\n",
              "      <td>0.005269</td>\n",
              "      <td>0.009369</td>\n",
              "      <td>0.006091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.362836</td>\n",
              "      <td>0.000246</td>\n",
              "      <td>0.205607</td>\n",
              "      <td>0.249477</td>\n",
              "      <td>0.292944</td>\n",
              "      <td>0.173261</td>\n",
              "      <td>0.003568</td>\n",
              "      <td>0.017938</td>\n",
              "      <td>0.024518</td>\n",
              "      <td>0.053661</td>\n",
              "      <td>0.019159</td>\n",
              "      <td>0.004279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.585425</td>\n",
              "      <td>0.004071</td>\n",
              "      <td>0.179245</td>\n",
              "      <td>0.338822</td>\n",
              "      <td>0.437278</td>\n",
              "      <td>0.906123</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.129159</td>\n",
              "      <td>0.011000</td>\n",
              "      <td>0.258179</td>\n",
              "      <td>0.035544</td>\n",
              "      <td>0.180510</td>\n",
              "      <td>0.009646</td>\n",
              "      <td>0.014956</td>\n",
              "      <td>0.602130</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.162112</td>\n",
              "      <td>0.308310</td>\n",
              "      <td>0.413564</td>\n",
              "      <td>0.892249</td>\n",
              "      <td>0.003636</td>\n",
              "      <td>0.175768</td>\n",
              "      <td>0.006719</td>\n",
              "      <td>0.259428</td>\n",
              "      <td>0.094145</td>\n",
              "      <td>0.180721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.938755</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.539320</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.179138</td>\n",
              "      <td>0.368762</td>\n",
              "      <td>0.468559</td>\n",
              "      <td>0.051533</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.057182</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.414668</td>\n",
              "      <td>0.071667</td>\n",
              "      <td>0.008350</td>\n",
              "      <td>0.004935</td>\n",
              "      <td>0.500785</td>\n",
              "      <td>0.558788</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>0.157139</td>\n",
              "      <td>0.333838</td>\n",
              "      <td>0.442628</td>\n",
              "      <td>0.131869</td>\n",
              "      <td>0.000795</td>\n",
              "      <td>0.064404</td>\n",
              "      <td>0.012072</td>\n",
              "      <td>0.403050</td>\n",
              "      <td>0.094385</td>\n",
              "      <td>0.003853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.647420</td>\n",
              "      <td>0.002662</td>\n",
              "      <td>0.176094</td>\n",
              "      <td>0.304391</td>\n",
              "      <td>0.450500</td>\n",
              "      <td>0.928055</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.185172</td>\n",
              "      <td>0.004000</td>\n",
              "      <td>0.271801</td>\n",
              "      <td>0.044676</td>\n",
              "      <td>0.552020</td>\n",
              "      <td>0.061784</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.677610</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.155192</td>\n",
              "      <td>0.271510</td>\n",
              "      <td>0.417227</td>\n",
              "      <td>0.770894</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.190694</td>\n",
              "      <td>0.002613</td>\n",
              "      <td>0.299106</td>\n",
              "      <td>0.107275</td>\n",
              "      <td>0.557350</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        25        26        27\n",
              "0  0.000000  0.000264  0.162163  ...  0.188011  0.122987  0.009348\n",
              "1  0.000000  0.000075  0.353761  ...  0.053661  0.019159  0.004279\n",
              "2  0.000000  0.000018  0.585425  ...  0.259428  0.094145  0.180721\n",
              "3  0.938755  0.000013  0.539320  ...  0.403050  0.094385  0.003853\n",
              "4  0.000000  0.000052  0.647420  ...  0.299106  0.107275  0.557350\n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F45G02gc8YmH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "9f446f81-88d7-460d-ba74-bdaf723cce74"
      },
      "source": [
        "# Fit a logistic regression model using sklearn (see: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
        "# Create the model object\n",
        "modelLg = LogisticRegression(random_state=0,penalty='none',fit_intercept=True, max_iter=1000)\n",
        "# Fit the model using the training data\n",
        "modelLg.fit(X_train, Y_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='none',\n",
              "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-yYdgmJ8YmM",
        "colab_type": "text"
      },
      "source": [
        "### Note: \n",
        "sklearn is a popular ML libary that we will primarily use in the course. While sklearn allows to run\n",
        "regressions it does not provide regression table outputs (with p-values, standard errors etc.). \n",
        "While those table are very common in econometrics they are not commonly considered in the ML \n",
        "community. For illustrative puposes we do the calculation for a regrssion table manually, however,\n",
        "there is also a \"statsmodels\" libary in python that does this automatically (see below). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWVvG9Nb8YmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to calculate pvalues and standard errors for a scikit-learn logisticRegression\n",
        "# Source: https://stackoverflow.com/questions/25122999/scikit-learn-how-to-check-coefficients-significance\n",
        "def logit_pvalue(model, x):\n",
        "    \"\"\" Calculate z-scores for scikit-learn LogisticRegression.\n",
        "    parameters:\n",
        "        model: fitted sklearn.linear_model.LogisticRegression with intercept and large C\n",
        "        x:     matrix on which the model was fit\n",
        "    This function uses asymtptics for maximum likelihood estimates.\n",
        "    \"\"\"\n",
        "    p = model.predict_proba(x)\n",
        "    n = len(p)\n",
        "    m = len(model.coef_[0]) + 1\n",
        "    # m = len(model.coef_[0])\n",
        "    # coefs = model.coef_[0]\n",
        "    coefs = np.concatenate([model.intercept_, model.coef_[0]])\n",
        "    x_full = np.matrix(np.insert(np.array(x), 0, 1, axis = 1))\n",
        "    ans = np.zeros((m, m))\n",
        "    for i in range(n):\n",
        "        ans = ans + np.dot(np.transpose(x_full[i, :]), x_full[i, :]) * p[i,1] * p[i, 0]\n",
        "    vcov = np.linalg.inv(np.matrix(ans))\n",
        "    se = np.sqrt(np.diag(vcov))\n",
        "    t =  coefs/se  \n",
        "    p = (1 - norm.cdf(abs(t))) * 2\n",
        "    return se, p"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ORdUGhf8YmR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "outputId": "64a22647-2d7e-487a-8ab8-68d55af01047"
      },
      "source": [
        "# Use the previously created function to create a regression output table\n",
        "se, p = logit_pvalue(modelLg, X_train)\n",
        "coefs = np.concatenate([modelLg.intercept_, modelLg.coef_[0]]).T\n",
        "resCoef = pd.DataFrame(coefs,index=['constant']+lstCols)\n",
        "resCoef.columns = ['coef']\n",
        "resCoef['se'] = se\n",
        "resCoef['pval'] = p\n",
        "resCoef"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>coef</th>\n",
              "      <th>se</th>\n",
              "      <th>pval</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>constant</th>\n",
              "      <td>-1.940124</td>\n",
              "      <td>0.034343</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wdpa_2017</th>\n",
              "      <td>-0.467926</td>\n",
              "      <td>0.064253</td>\n",
              "      <td>3.275158e-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>population_2015</th>\n",
              "      <td>-0.158076</td>\n",
              "      <td>0.514422</td>\n",
              "      <td>7.586236e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chirps_2017</th>\n",
              "      <td>-0.167554</td>\n",
              "      <td>0.691338</td>\n",
              "      <td>8.084994e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>defor_2017</th>\n",
              "      <td>14.225848</td>\n",
              "      <td>0.286949</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>maize</th>\n",
              "      <td>1.651575</td>\n",
              "      <td>0.769411</td>\n",
              "      <td>3.182962e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>soy</th>\n",
              "      <td>-0.620290</td>\n",
              "      <td>0.576509</td>\n",
              "      <td>2.819534e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sugarcane</th>\n",
              "      <td>0.215807</td>\n",
              "      <td>0.509735</td>\n",
              "      <td>6.720250e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perc_treecover</th>\n",
              "      <td>0.635648</td>\n",
              "      <td>0.032853</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perm_water</th>\n",
              "      <td>0.580214</td>\n",
              "      <td>0.263381</td>\n",
              "      <td>2.759852e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>travel_min</th>\n",
              "      <td>-0.727544</td>\n",
              "      <td>0.343680</td>\n",
              "      <td>3.426622e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cropland</th>\n",
              "      <td>-0.046412</td>\n",
              "      <td>0.189232</td>\n",
              "      <td>8.062527e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean_elev</th>\n",
              "      <td>-4.419300</td>\n",
              "      <td>0.204336</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sd_elev</th>\n",
              "      <td>0.558211</td>\n",
              "      <td>0.136419</td>\n",
              "      <td>4.278631e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>near_road</th>\n",
              "      <td>-6.744318</td>\n",
              "      <td>1.792425</td>\n",
              "      <td>1.681029e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>defor_2017_lag_1st_order</th>\n",
              "      <td>3.714795</td>\n",
              "      <td>0.169721</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wdpa_2017_lag_1st_order</th>\n",
              "      <td>-0.913002</td>\n",
              "      <td>0.071462</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chirps_2017_lag_1st_order</th>\n",
              "      <td>3.111312</td>\n",
              "      <td>0.680071</td>\n",
              "      <td>4.762685e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>population_2015_lag_1st_order</th>\n",
              "      <td>3.724620</td>\n",
              "      <td>0.399375</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>maize_lag_1st_order</th>\n",
              "      <td>-1.806842</td>\n",
              "      <td>0.749900</td>\n",
              "      <td>1.597692e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>soy_lag_1st_order</th>\n",
              "      <td>2.674067</td>\n",
              "      <td>0.557706</td>\n",
              "      <td>1.628688e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sugarcane_lag_1st_order</th>\n",
              "      <td>-4.188577</td>\n",
              "      <td>0.502063</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perc_treecover_lag_1st_order</th>\n",
              "      <td>0.124474</td>\n",
              "      <td>0.047211</td>\n",
              "      <td>8.375164e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perm_water_lag_1st_order</th>\n",
              "      <td>-4.828390</td>\n",
              "      <td>0.439273</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>travel_min_lag_1st_order</th>\n",
              "      <td>-1.948750</td>\n",
              "      <td>0.352742</td>\n",
              "      <td>3.302795e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cropland_lag_1st_order</th>\n",
              "      <td>0.621928</td>\n",
              "      <td>0.203516</td>\n",
              "      <td>2.243741e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean_elev_lag_1st_order</th>\n",
              "      <td>2.930828</td>\n",
              "      <td>0.207382</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sd_elev_lag_1st_order</th>\n",
              "      <td>1.817447</td>\n",
              "      <td>0.099775</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>near_road_lag_1st_order</th>\n",
              "      <td>7.614431</td>\n",
              "      <td>1.770958</td>\n",
              "      <td>1.710974e-05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    coef        se          pval\n",
              "constant                       -1.940124  0.034343  0.000000e+00\n",
              "wdpa_2017                      -0.467926  0.064253  3.275158e-13\n",
              "population_2015                -0.158076  0.514422  7.586236e-01\n",
              "chirps_2017                    -0.167554  0.691338  8.084994e-01\n",
              "defor_2017                     14.225848  0.286949  0.000000e+00\n",
              "maize                           1.651575  0.769411  3.182962e-02\n",
              "soy                            -0.620290  0.576509  2.819534e-01\n",
              "sugarcane                       0.215807  0.509735  6.720250e-01\n",
              "perc_treecover                  0.635648  0.032853  0.000000e+00\n",
              "perm_water                      0.580214  0.263381  2.759852e-02\n",
              "travel_min                     -0.727544  0.343680  3.426622e-02\n",
              "cropland                       -0.046412  0.189232  8.062527e-01\n",
              "mean_elev                      -4.419300  0.204336  0.000000e+00\n",
              "sd_elev                         0.558211  0.136419  4.278631e-05\n",
              "near_road                      -6.744318  1.792425  1.681029e-04\n",
              "defor_2017_lag_1st_order        3.714795  0.169721  0.000000e+00\n",
              "wdpa_2017_lag_1st_order        -0.913002  0.071462  0.000000e+00\n",
              "chirps_2017_lag_1st_order       3.111312  0.680071  4.762685e-06\n",
              "population_2015_lag_1st_order   3.724620  0.399375  0.000000e+00\n",
              "maize_lag_1st_order            -1.806842  0.749900  1.597692e-02\n",
              "soy_lag_1st_order               2.674067  0.557706  1.628688e-06\n",
              "sugarcane_lag_1st_order        -4.188577  0.502063  0.000000e+00\n",
              "perc_treecover_lag_1st_order    0.124474  0.047211  8.375164e-03\n",
              "perm_water_lag_1st_order       -4.828390  0.439273  0.000000e+00\n",
              "travel_min_lag_1st_order       -1.948750  0.352742  3.302795e-08\n",
              "cropland_lag_1st_order          0.621928  0.203516  2.243741e-03\n",
              "mean_elev_lag_1st_order         2.930828  0.207382  0.000000e+00\n",
              "sd_elev_lag_1st_order           1.817447  0.099775  0.000000e+00\n",
              "near_road_lag_1st_order         7.614431  1.770958  1.710974e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRYFl12K8YmV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        },
        "outputId": "38b866da-5055-434f-c8bd-6a0b5d71ff91"
      },
      "source": [
        "# Confirm the results using statsmodels\n",
        "import statsmodels.api as sm\n",
        "# Add constant to X matrix\n",
        "X_train_const = np.matrix(np.insert(np.array(X_train), 0, 1, axis = 1))\n",
        "\n",
        "# Define the logit regression\n",
        "logit = sm.Logit(Y_train,X_train_const)\n",
        "\n",
        "# Set the names of the explanatory variables\n",
        "logit.data.xnames = exog_names=['const']+lstCols\n",
        "\n",
        "# fit the model\n",
        "result = logit.fit()\n",
        "# Print the summary table\n",
        "print(result.summary())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.468908\n",
            "         Iterations 7\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:           D_defor_2018   No. Observations:               199952\n",
            "Model:                          Logit   Df Residuals:                   199923\n",
            "Method:                           MLE   Df Model:                           28\n",
            "Date:                Mon, 06 Jul 2020   Pseudo R-squ.:                  0.1463\n",
            "Time:                        08:48:46   Log-Likelihood:                -93759.\n",
            "converged:                       True   LL-Null:                   -1.0983e+05\n",
            "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
            "=================================================================================================\n",
            "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
            "-------------------------------------------------------------------------------------------------\n",
            "const                            -1.9386      0.034    -56.447      0.000      -2.006      -1.871\n",
            "wdpa_2017                        -0.4685      0.064     -7.291      0.000      -0.594      -0.343\n",
            "population_2015                  -0.1314      0.514     -0.256      0.798      -1.138       0.875\n",
            "chirps_2017                      -0.1106      0.691     -0.160      0.873      -1.466       1.244\n",
            "defor_2017                       14.2316      0.287     49.588      0.000      13.669      14.794\n",
            "maize                             1.7750      0.769      2.307      0.021       0.267       3.283\n",
            "soy                              -0.7496      0.577     -1.300      0.194      -1.880       0.380\n",
            "sugarcane                         0.2790      0.510      0.547      0.584      -0.720       1.278\n",
            "perc_treecover                    0.6357      0.033     19.350      0.000       0.571       0.700\n",
            "perm_water                        0.6038      0.263      2.295      0.022       0.088       1.119\n",
            "travel_min                       -0.6934      0.344     -2.017      0.044      -1.367      -0.020\n",
            "cropland                         -0.0331      0.189     -0.175      0.861      -0.404       0.338\n",
            "mean_elev                        -4.4226      0.204    -21.640      0.000      -4.823      -4.022\n",
            "sd_elev                           0.5607      0.136      4.109      0.000       0.293       0.828\n",
            "near_road                        -7.1358      1.793     -3.980      0.000     -10.649      -3.622\n",
            "defor_2017_lag_1st_order          3.7109      0.170     21.865      0.000       3.378       4.044\n",
            "wdpa_2017_lag_1st_order          -0.9122      0.071    -12.764      0.000      -1.052      -0.772\n",
            "chirps_2017_lag_1st_order         3.0545      0.680      4.491      0.000       1.722       4.387\n",
            "population_2015_lag_1st_order     3.7075      0.399      9.288      0.000       2.925       4.490\n",
            "maize_lag_1st_order              -1.9274      0.750     -2.570      0.010      -3.397      -0.457\n",
            "soy_lag_1st_order                 2.8002      0.558      5.021      0.000       1.707       3.893\n",
            "sugarcane_lag_1st_order          -4.2509      0.502     -8.466      0.000      -5.235      -3.267\n",
            "perc_treecover_lag_1st_order      0.1250      0.047      2.648      0.008       0.032       0.218\n",
            "perm_water_lag_1st_order         -4.8646      0.440    -11.053      0.000      -5.727      -4.002\n",
            "travel_min_lag_1st_order         -1.9837      0.353     -5.623      0.000      -2.675      -1.292\n",
            "cropland_lag_1st_order            0.6076      0.204      2.985      0.003       0.209       1.007\n",
            "mean_elev_lag_1st_order           2.9342      0.207     14.146      0.000       2.528       3.341\n",
            "sd_elev_lag_1st_order             1.8144      0.100     18.182      0.000       1.619       2.010\n",
            "near_road_lag_1st_order           8.0021      1.771      4.518      0.000       4.530      11.474\n",
            "=================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hwbd1OKA8Ymg",
        "colab_type": "text"
      },
      "source": [
        "## Train your first very (very) simple neural network using sklearn\n",
        "Now use a neural network for the same problem. In the course you will see that this is actually equivalent to a logistic regression, hence a logistic regression is in fact a specific form of a neural network!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_6bKms58Ymg",
        "colab_type": "text"
      },
      "source": [
        "### Performe a hyper parameter search to tune the learning rate for training the NN. \n",
        "This step is optional and takes a while. You can also run the next cell, \n",
        "using a fixed learning rate. The learning rate was determine using this hyper parameter search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArwpfQ5I8Ymi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b6e0c903-8d2f-4e18-c38a-a1d947c6cdf8"
      },
      "source": [
        "from sklearn.utils.fixes import loguniform\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "param_grid = {\n",
        "    'alpha':loguniform(1e-6, 1e-1)}\n",
        "\n",
        "modelNN = MLPClassifier(solver='lbfgs', activation = 'identity',\n",
        "                     hidden_layer_sizes=(1), random_state=1, verbose=True,max_iter=200)\n",
        "\n",
        "\n",
        "clf = RandomizedSearchCV(modelNN, param_grid, random_state=0,n_iter=10,cv=5)\n",
        "modelNN = clf.fit(X_train_const, Y_train)\n",
        "modelNN.best_params_"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.00013130280280658594}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuVenVfW8Ymk",
        "colab_type": "text"
      },
      "source": [
        "### Train the Neural Network with a fixed set of hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPdSWMNX8Yml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "5b450053-cf6e-4990-c9fd-373ffa5a6d02"
      },
      "source": [
        "modelNN = MLPClassifier(solver='lbfgs', alpha=8.264328927007723e-05,activation = 'identity',\n",
        "                     hidden_layer_sizes=(1), random_state=1, verbose=True,max_iter=200)\n",
        "\n",
        "modelNN.fit(X_train_const, Y_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='identity', alpha=8.264328927007723e-05,\n",
              "              batch_size='auto', beta_1=0.9, beta_2=0.999, early_stopping=False,\n",
              "              epsilon=1e-08, hidden_layer_sizes=1, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=1, shuffle=True, solver='lbfgs',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N3xe5ve8Ymo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "outputId": "c149fc9f-211f-4eab-c084-a8118911c299"
      },
      "source": [
        "# Add the estimated coefficient of the NN to the regression table we created above-\n",
        "# In the course we will discuss why the estimated coefficient are similar. \n",
        "#    modelNN.coefs_[0] are the coefficients of the first layer\n",
        "#    modelNN.coefs_[1][0][0] is the coefficients of the hidden layer\n",
        "resCoef['coef_NN'] = modelNN.coefs_[0]*modelNN.coefs_[1][0][0]\n",
        "resCoef"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>coef</th>\n",
              "      <th>se</th>\n",
              "      <th>pval</th>\n",
              "      <th>coef_NN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>constant</th>\n",
              "      <td>-1.940124</td>\n",
              "      <td>0.034343</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-0.230493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wdpa_2017</th>\n",
              "      <td>-0.467926</td>\n",
              "      <td>0.064253</td>\n",
              "      <td>3.275158e-13</td>\n",
              "      <td>-0.459015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>population_2015</th>\n",
              "      <td>-0.158076</td>\n",
              "      <td>0.514422</td>\n",
              "      <td>7.586236e-01</td>\n",
              "      <td>0.482185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chirps_2017</th>\n",
              "      <td>-0.167554</td>\n",
              "      <td>0.691338</td>\n",
              "      <td>8.084994e-01</td>\n",
              "      <td>1.145597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>defor_2017</th>\n",
              "      <td>14.225848</td>\n",
              "      <td>0.286949</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>14.016413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>maize</th>\n",
              "      <td>1.651575</td>\n",
              "      <td>0.769411</td>\n",
              "      <td>3.182962e-02</td>\n",
              "      <td>0.331256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>soy</th>\n",
              "      <td>-0.620290</td>\n",
              "      <td>0.576509</td>\n",
              "      <td>2.819534e-01</td>\n",
              "      <td>0.995630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sugarcane</th>\n",
              "      <td>0.215807</td>\n",
              "      <td>0.509735</td>\n",
              "      <td>6.720250e-01</td>\n",
              "      <td>-0.808113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perc_treecover</th>\n",
              "      <td>0.635648</td>\n",
              "      <td>0.032853</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.644819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perm_water</th>\n",
              "      <td>0.580214</td>\n",
              "      <td>0.263381</td>\n",
              "      <td>2.759852e-02</td>\n",
              "      <td>0.627011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>travel_min</th>\n",
              "      <td>-0.727544</td>\n",
              "      <td>0.343680</td>\n",
              "      <td>3.426622e-02</td>\n",
              "      <td>-1.182644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cropland</th>\n",
              "      <td>-0.046412</td>\n",
              "      <td>0.189232</td>\n",
              "      <td>8.062527e-01</td>\n",
              "      <td>-0.033465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean_elev</th>\n",
              "      <td>-4.419300</td>\n",
              "      <td>0.204336</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-4.578227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sd_elev</th>\n",
              "      <td>0.558211</td>\n",
              "      <td>0.136419</td>\n",
              "      <td>4.278631e-05</td>\n",
              "      <td>0.563164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>near_road</th>\n",
              "      <td>-6.744318</td>\n",
              "      <td>1.792425</td>\n",
              "      <td>1.681029e-04</td>\n",
              "      <td>0.197836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>defor_2017_lag_1st_order</th>\n",
              "      <td>3.714795</td>\n",
              "      <td>0.169721</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.832024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wdpa_2017_lag_1st_order</th>\n",
              "      <td>-0.913002</td>\n",
              "      <td>0.071462</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-0.923049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chirps_2017_lag_1st_order</th>\n",
              "      <td>3.111312</td>\n",
              "      <td>0.680071</td>\n",
              "      <td>4.762685e-06</td>\n",
              "      <td>1.843058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>population_2015_lag_1st_order</th>\n",
              "      <td>3.724620</td>\n",
              "      <td>0.399375</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.452860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>maize_lag_1st_order</th>\n",
              "      <td>-1.806842</td>\n",
              "      <td>0.749900</td>\n",
              "      <td>1.597692e-02</td>\n",
              "      <td>-0.510434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>soy_lag_1st_order</th>\n",
              "      <td>2.674067</td>\n",
              "      <td>0.557706</td>\n",
              "      <td>1.628688e-06</td>\n",
              "      <td>1.085162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sugarcane_lag_1st_order</th>\n",
              "      <td>-4.188577</td>\n",
              "      <td>0.502063</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-3.172481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perc_treecover_lag_1st_order</th>\n",
              "      <td>0.124474</td>\n",
              "      <td>0.047211</td>\n",
              "      <td>8.375164e-03</td>\n",
              "      <td>0.114699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perm_water_lag_1st_order</th>\n",
              "      <td>-4.828390</td>\n",
              "      <td>0.439273</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-4.504573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>travel_min_lag_1st_order</th>\n",
              "      <td>-1.948750</td>\n",
              "      <td>0.352742</td>\n",
              "      <td>3.302795e-08</td>\n",
              "      <td>-1.520611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cropland_lag_1st_order</th>\n",
              "      <td>0.621928</td>\n",
              "      <td>0.203516</td>\n",
              "      <td>2.243741e-03</td>\n",
              "      <td>0.615071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean_elev_lag_1st_order</th>\n",
              "      <td>2.930828</td>\n",
              "      <td>0.207382</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.089948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sd_elev_lag_1st_order</th>\n",
              "      <td>1.817447</td>\n",
              "      <td>0.099775</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.822710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>near_road_lag_1st_order</th>\n",
              "      <td>7.614431</td>\n",
              "      <td>1.770958</td>\n",
              "      <td>1.710974e-05</td>\n",
              "      <td>0.743052</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    coef        se          pval    coef_NN\n",
              "constant                       -1.940124  0.034343  0.000000e+00  -0.230493\n",
              "wdpa_2017                      -0.467926  0.064253  3.275158e-13  -0.459015\n",
              "population_2015                -0.158076  0.514422  7.586236e-01   0.482185\n",
              "chirps_2017                    -0.167554  0.691338  8.084994e-01   1.145597\n",
              "defor_2017                     14.225848  0.286949  0.000000e+00  14.016413\n",
              "maize                           1.651575  0.769411  3.182962e-02   0.331256\n",
              "soy                            -0.620290  0.576509  2.819534e-01   0.995630\n",
              "sugarcane                       0.215807  0.509735  6.720250e-01  -0.808113\n",
              "perc_treecover                  0.635648  0.032853  0.000000e+00   0.644819\n",
              "perm_water                      0.580214  0.263381  2.759852e-02   0.627011\n",
              "travel_min                     -0.727544  0.343680  3.426622e-02  -1.182644\n",
              "cropland                       -0.046412  0.189232  8.062527e-01  -0.033465\n",
              "mean_elev                      -4.419300  0.204336  0.000000e+00  -4.578227\n",
              "sd_elev                         0.558211  0.136419  4.278631e-05   0.563164\n",
              "near_road                      -6.744318  1.792425  1.681029e-04   0.197836\n",
              "defor_2017_lag_1st_order        3.714795  0.169721  0.000000e+00   3.832024\n",
              "wdpa_2017_lag_1st_order        -0.913002  0.071462  0.000000e+00  -0.923049\n",
              "chirps_2017_lag_1st_order       3.111312  0.680071  4.762685e-06   1.843058\n",
              "population_2015_lag_1st_order   3.724620  0.399375  0.000000e+00   3.452860\n",
              "maize_lag_1st_order            -1.806842  0.749900  1.597692e-02  -0.510434\n",
              "soy_lag_1st_order               2.674067  0.557706  1.628688e-06   1.085162\n",
              "sugarcane_lag_1st_order        -4.188577  0.502063  0.000000e+00  -3.172481\n",
              "perc_treecover_lag_1st_order    0.124474  0.047211  8.375164e-03   0.114699\n",
              "perm_water_lag_1st_order       -4.828390  0.439273  0.000000e+00  -4.504573\n",
              "travel_min_lag_1st_order       -1.948750  0.352742  3.302795e-08  -1.520611\n",
              "cropland_lag_1st_order          0.621928  0.203516  2.243741e-03   0.615071\n",
              "mean_elev_lag_1st_order         2.930828  0.207382  0.000000e+00   3.089948\n",
              "sd_elev_lag_1st_order           1.817447  0.099775  0.000000e+00   1.822710\n",
              "near_road_lag_1st_order         7.614431  1.770958  1.710974e-05   0.743052"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGP8hkW28Yms",
        "colab_type": "text"
      },
      "source": [
        "### Compare the model outcomes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT1FnBrn8Ymu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add constant to the test data\n",
        "X_test_const = np.matrix(np.insert(np.array(X_test), 0, 1, axis = 1))\n",
        "# Get predicted values from logit model \n",
        "Y_test_Lg = modelLg.predict(X_test)\n",
        "# Get predicted values from NN model \n",
        "Y_test_NN = modelNN.predict(X_test_const)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um1zNIHj8Ymx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a8aecba2-9d6b-43d0-d1e3-14ac85a34f17"
      },
      "source": [
        "score_Lg = np.sum(Y_test==Y_test_Lg)/Y_test.shape[0]\n",
        "score_NN = np.sum(Y_test==Y_test_NN)/Y_test.shape[0]\n",
        "print('Score lg (R²): ',score_Lg)\n",
        "print('Score NN (R²): ',score_NN)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score lg (R²):  0.7853084740337681\n",
            "Score NN (R²):  0.7854084980395295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKKjn2W58Ym2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "2b105a94-4638-430b-c1d0-f1272e9b6423"
      },
      "source": [
        "# plot the predicte probabalities of the logit model\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
        "\n",
        "pd.DataFrame(modelLg.predict_proba(X_test))[1].hist(bins=100,ax=ax1)\n",
        "pd.DataFrame(modelNN.predict_proba(X_test_const))[1].hist(bins=100,ax=ax2)\n",
        "fig.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DerYBK448Ym5",
        "colab_type": "text"
      },
      "source": [
        "### Well done!!! \n",
        "Now it is your turn. Play around with the notebook to make your very first steps with numpy/pandas and sklearn. In the intro above there are some suggestions of what you can try.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTeZV4aa8Ym6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}